# AWS Amazon Web Server

## Good to know concepts
- **What is a client-server model?** In computing, a client can be a web browser or desktop application that a person interacts with to make requests to computer servers. A server can be services such as Amazon Elastic Compute Cloud (Amazon EC2), a type of virtual server.
- **What is cloud computing?** Cloud computing is the on-demand delivery of IT resources over the Internet with pay-as-you-go pricing.
- **Elasticity** With cloud computing, you don’t have to over-provision resources up front to handle peak levels of business activity in the future. Instead, you provision the amount of resources that you actually need. You can scale these resources up or down to instantly grow and shrink capacity as your business needs change.
- **Types of cloud computing**: There are 3 types of them: Infrastructure or Platform or Software as a Service. Alternatively: Iaas, PaaS and SaaS. These are arranged from more to less flexibility.
- **Multitenancy**: the idea of sharing underlying hardware between virtual machines.
- **Serverless** means that your code runs on servers, but you do not need to provision or manage these servers. With serverless computing, you can focus more on innovating new products and features instead of maintaining servers. The opposite of this way of working is the EC2 (i.e. virtual server) instance that lets you run virtual servers in the cloud. If you have applications that you want to run in Amazon EC2, you must do the following:
  - Provision instances (virtual servers).
  - Upload your code.
  - Continue to manage the instances while your application is running.
- **Shared responsibility model** is the idea that both customer and AWS is responsible for keeping resources secure. AWS is responsible for some parts of your environment and you (the customer) are responsible for other parts. The shared responsibility model divides into customer responsibilities (commonly referred to as “security in the cloud”) and AWS responsibilities (commonly referred to as “security of the cloud”).
- **Caching** is applied to improve application performance. The cache is a piece of memory that has much faster read/write time (around an order of magnitude faster).
- **AWS service endpoints** To connect programmatically to an AWS service, you use an endpoint. An endpoint is the URL of the entry point for an AWS web service. 
- **AMI** is an Amazon Machine Image. It is a frozen instance of a server that you can select and instantiate on a new virtual server.
- **Measured service** is the idea that a consumer should be able to use computing resources on a pay-as- you-use basis.
- **Availability** is the idea that the time to provision a ready-to-use resource in the cloud is significantly lower than having to set up a similar resource in-house.
- **Cloud computing** is defined ba model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.

## Quick reference on AWS offers
- **Elastic Inference** allows you to attach low-cost GPU-powered acceleration to Amazon EC2 and Sagemaker instances or Amazon ECS tasks, to reduce the cost of running deep learning inference by up to 75%. Amazon Elastic Inference supports TensorFlow, Apache MXNet, PyTorch and ONNX models.

- **S3 bucket** stand for Simple Storage Service (S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance.  A bucket is nothing more than a folder. It cannot be used to install an operating system; thus, it cannot provide the storage for an EC2 instance. Customers of all sizes and industries can use Amazon S3 to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. There are 6 types:
  - S3 Standard
  - S3 Standard-Infrequent Access (S3 Standard-IA)
  - S3 One Zone-Infrequent Access (S3 One Zone-IA)
  - S3 Intelligent-Tiering
  - S3 Glacier
  - S3 Glacier Deep Archive 

- **SageMaker** is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. It provides the tools to build, train and deploy machine learning (ML) models for predictive analytics applications. The platform automates the tedious work of building a production-ready artificial intelligence (AI) pipeline. *Why would you use it?* AWS SageMaker provides more elegant ways to train, test and deploy models with tools like Inference pipelines, Batch transform, multi model endpoints, A/B testing with production variants, Hyper-parameter tuning, Auto scaling etc.

- [[Notes]](https://github.com/kyaiooiayk/MLOps-Machine-Learning-Operations/tree/master/tutorials/AWS/AWS_EC2) **EC2 (Amazon's Elastic Compute Cloud) instance** is a virtual server for running applications on the Amazon Web Services (AWS) infrastructure. It provides secure, resizable compute capacity in the cloud. 

- **Amazon EC2 Auto Scaling** enables you to automatically add or remove Amazon EC2 instances in response to changing application demand. By automatically scaling your instances in and out as needed, you are able to maintain a greater sense of application availability. Two approaches are available: 
  - Dynamic scaling responds to changing demand. 
  - Predictive scaling automatically schedules instances based on predicted demand.

- **Amazon EC2 instance types**: 
  - General purpose instances: balances compute, memory, and networking resources
  - Compute optimized instances: compute-intensive tasks. Offers high-performance processors. Used for a batch processing workload.
  - Memory optimized instances: memory-intensive task. Ideal for high-performance databases.
  - Accelerated computing instances: GPUs? 
  - Storage optimized instances: suitable for data warehousing applications

- **Elastic Load Balancing** Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances. This means that as you add or remove Amazon EC2 instances in response to the amount of incoming traffic, these requests route to the load balancer first. Then, the requests spread across multiple resources that will handle them. Although Elastic Load Balancing and Amazon EC2 Auto Scaling are separate services, they work together to help ensure that applications running in Amazon EC2 can provide high performance and availability.  An example of Elastic Load Balancing Ensuring that no single Amazon EC2 instance has to carry the full workload on its own.

- **Amazon EC2 pricing**
  - On-Demand
  - Amazon EC2 Savings Plans
  - Reserved Instances
  - Spot Instances: ideal for workloads that can withstand interruptions. Compute costs by up to 90% over On-Demand costs.  AWS can reclaim the resorces anytime with a 2 minutes warning.
  - Dedicated Hosts: resources is not shared with anyone else.
 - [[Notes]](https://github.com/kyaiooiayk/MLOps-Machine-Learning-Operations/tree/master/tutorials/AWS/Lambda) **Lambda** is a serverless compute service that lets your code without provisioning or managing servers. “Serverless” doesn’t mean there is no server, it just means that you don’t care about the underlying infrastructure for your code and you only pay for what you use. Just upload your code as a ZIP file or container image, and Lambda automatically and precisely allocates compute execution power and runs your code based on the incoming request or event, for any scale of traffic. This is how AWS Lambda works:
    - You upload your code to Lambda. 
    - You set your code to trigger from an event source, such as AWS services, mobile applications, or HTTP endpoints.
    -  Lambda runs your code only when triggered. The trigger part is key to understand how they work.
    - You pay only for the compute time that you use. In the previous example of resizing images, you would pay only for the compute time that you use when uploading new images. Uploading the images triggers Lambda to run code for the image resizing function.
- **API Gateway** is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the “front door” for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications.
- **Boto3** is the name of the Python SDK(Software Development Kit) for AWS. It allows you to directly create, update, and delete AWS resources from your Python scripts. The same is true with APIs and SDKs. By definition, an SDK is a kit that includes instructions that allow developers to create systems and develop applications. APIs, on the other hand, are purpose-built for an express use — to allow communication between applications.
- **Amazon SageMaker Python SDK** SageMaker Python SDK provides several high-level abstractions for working with Amazon SageMaker.- **API vs. SDK** An API is simply an interface that allows software to interact with other software. If an API is a set of building blocks that allow for the creation of something, an SDK is a full-fledged workshop, facilitating creation far outside the scopes of what an API would allow. By definition, an SDK is a kit that includes instructions that allow developers to create systems and develop applications. APIs, on the other hand, are purpose-built for an express use — to allow communication between applications.
- **Amazon Simple Notification Service (Amazon SNS) & Amazon Simple Queue Service (Amazon SQS)** Suppose that you have an application with tightly coupled components comprising of databases, servers, the user interface, business logic, and so on. This type of architecture can be considered a monolithic application, but if a single component fails, other components fail, and possibly the entire application fails. In a microservices approach, application components are loosely coupled, thus if a single component fails, the other components continue to work. Two services facilitate application integration: Amazon Simple Notification Service (Amazon SNS) and Amazon Simple Queue Service (Amazon SQS).
  - Amazon SNS is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. Subscribers can be web servers, email addresses, AWS Lambda functions, or several other options.
  - Amazon SQS is a message queuing service. Using Amazon SQS, you can send, store, and receive messages between software components, without losing messages or requiring other services to be available. In Amazon SQS, an application sends messages into a queue. A user or service retrieves a message from the queue, processes it, and then deletes it from the queue.
 - **Amazon Elastic Container Service (Amazon ECS)** is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. Amazon ECS supports Docker containers.
- **Amazon Elastic Kubernetes Service (Amazon EKS)** is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale.
- **AWS Fargate** AWS Fargate is a serverless compute engine for containers. It works with both Amazon ECS and Amazon EKS. When using AWS Fargate, you do not need to provision or manage servers. AWS Fargate manages your server infrastructure for you.
- **AWS Elastic Beanstalk** With AWS Elastic Beanstalk, you provide code and configuration settings, and Elastic Beanstalk deploys the resources necessary to perform the following tasks:
  - Adjust capacity
  - Load balancing
  - Automatic scaling
  - Application health monitoring
- **AWS CloudFormation** With AWS CloudFormation, you can treat your infrastructure as code. This means that you can build an environment by writing lines of code instead of using the AWS Management Console to individually provision resources.
- **Amazon CloudFront** is best described as a global content delivery service. Edge location are site that Amazon CloudFront use to cache copies of content for faster delivery to users at any location. An edge location is a content-distribution end point for CloudFront. Amazon CloudFront is a secure content delivery service that integrates with Amazon’s S3 and allows caching of frequently used media files closer to the point of consumption. 
- **Amazon Outpost** it is used to extend AWS infrastructure and services to your on-premises data center.
- **Amazon Route 53** is a DNS web service which gives developers and businesses a reliable way to route end users to internet applications hosted in AWS. DNS can be thought as being the phone book of the internet. DNS resolution is the process of translating a domain name to an IP address. 
- **Instance store** is a store that provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance. When the instance is terminated, you lose any data in the instance store. Thus, instance stores for use cases that involve temporary data that you do not need in the long term.
- **Amazon Elastic Block Store (Amazon EBS)** is a service that provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all the data on the attached EBS volume remains available. Because EBS volumes are for data that needs to persist, it’s important to back up the data. You can take incremental backups of EBS volumes by creating Amazon EBS snapshots. It stores data in a *single* availability zone.
- **Amazon Elastic File System (Amazon EFS)** is a scalable file system used with AWS Cloud services and on-premises resources. As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications. It stores data in a *multiple* availability zone.
- **Amazon DynamoDB** is a key-value database service, thus NoSQL. It delivers single-digit millisecond performance at any scale. Nonrelational databases are sometimes referred to as “NoSQL databases” because they use structures other than rows and columns to organize data. One type of structural approach for nonrelational databases is key-value pairs. With key-value pairs, data is organized into items (keys), and items have attributes (values). You can think of attributes as being different features of your data. It is serveless which means you do not have to provision, patch and manage servers.
- **Amazon Redshift** is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and helps you to understand relationships and trends across your data.
- **AWS Database Migration Service (AWS DMS)** enables you to migrate relational databases, nonrelational databases, and other types of data stores. With AWS DMS, you move data between a source database and a target database. The source and target databases can be of the same type or different types. During the migration, your source database remains operational, reducing downtime for any applications that rely on the database. For example, suppose that you have a MySQL database that is stored on premises in an Amazon EC2 instance or in Amazon RDS. Consider the MySQL database to be your source database. Using AWS DMS, you could migrate your data to a target database, such as an Amazon Aurora database.
- **AWS Well-Architected Framework** helps you understand how to design and operate reliable, secure, efficient, and cost-effective systems in the AWS Cloud. It provides a way for you to consistently measure your architecture against best practices and design principles and identify areas for improvement.
- **AWS CloudTrail** captures API calls and related events made by or on behalf of your AWS account and delivers the log files to an Amazon S3 bucket that you specify. 
- **AWS Glue or Amazon EMR** are ETL services. They both use Apache Spark for your ETL. ETL requires a lot of reading and writing which take a lot of memory and disk I/O. For this reason the services use a framework like Apache Spark, which can handle large amounts of data easily for ETL.
- **AWS IAM** Amazon Identity and Access Management (IAM) lets you securely control who can access your AWS resources, what resources they can access, and what they can do with these resources. AWS account supports using multifactor authentication (MFA). A policy is a JSON document that grants permissions to a user, group, or role.

## Ways to interact with AWS services
  - Via the **AWS Management Console** which is a web-based interface for accessing and managing AWS services. Used if you are are managing or administering services.
  - Via the **AWS Command Line Interface (AWS CLI)** To save time when making API requests, you can use the AWS CLI. AWS CLI enables you to control multiple AWS services directly from the command line within one tool. AWS CLI is available for users on Windows, macOS, and Linux. Used if you are a DevOps.
  - Via **Software Development Kits (SDKs)** Another option for accessing and managing AWS services is the software development kits (SDKs). SDKs make it easier for you to use AWS services through an API designed for your programming language or platform. SDKs enable you to use AWS services with your existing applications or create entirely new applications that will run on AWS. Used if you are an app developer.
  - Via **RESTful** web services. Keep in mind that AWS is a collection of RESTful web services.

## I have an ML App in Flask and I want to deploy it via AWS
I have a ML Flask app API capable to do some real-time inference. I'd like to deployt it to the internet via AWS. There are at least 5 ways (hence this list is not exhaustive):
  - **Deploy it on an EC2 Instance** which the simplest but least robust. This entitles to acquire a virtual machine in the cloud, making it accessible to the internet, and starting your application on it. Ideal for quick showcase demos. If your app is small enough, it’ll cost you literally nothing to host and you can have it up in as little as 5 minutes. No need for a Docker image but just some simple linux command line. Requires lots of hacky manual setup not suitable for real production deployments.
  - **Create an AWS Lambda Function** AWS Lambda is a service for deploying serverless functions. “Serverless” doesn’t mean there is no server, it just means that you don’t care about the underlying infrastructure for your code and you only pay for what you use. While not ideal for some more complex use cases, it is ideal for simple and repeatable code. It’s scalable, extremely cheap. It requires an API Gateway, but it is far more robust than a standalone EC2 machine. For production, this would probably be the cheapest option.
  - **Containerize it and Deploy it with Elastic Container Service (ECS)** Like Kuberenetes, ECS is a container orchestration service for deploying applications. The difference is the distribution of responsibilities. Instead of the user being responsible for some lower-level infrastructure concerns you’d have to take care of in Kubernetes, you have AWS do it for you. ECS is similar to Lambda in that it abstracts away infrastructure concerns. In terms of flexibility, it sits in between Lambda and the highly flexible Kubernetes.  
  - **Containerize it and Deploy it on Kubernetes (EKS)** Kubernetes is one of the go-to options for managing and scaling containerized applications nowadays. Unlike more managed container orchestration solutions like ECS, Kubernetes provides granular control of your machine learning app. However, it comes at a bit of a cost. Unlike requisitioning a single instance on which to deploy your app, you now have to manage an entire Kubernetes cluster. Deploying an application and managing a cluster can prove no simple task for new users.
  - **Create a Sagemaker Endpoint** AWS Sagemaker is a first-class suite of ML tools for the cloud. From hosted to jupyter notebooks to easy model endpoints, the experience with Sagemaker will probably feel like creating deployments locally on your machine. Of course, the highly specific and managed nature of this solution could increase the cost.

## 4 ways to train and deploy ML models in SageMaker
  - Training and deploying inside SageMaker , both using SageMaker’s own built-in algorithm containers (pls note these are AWS managed containers).
  - Training our model locally/outside SageMaker and then use SageMaker’s built-in algorithm container to just deploy the locally trained model (Bring Your Own Model type ).
  - Use SageMaker’s (AWS managed) built-in algorithms containers, but customize the training as per needs with our own scripts ( Bring Your Own Model type).
  - Train our model in whatever method and then bring your container to SageMaker and deploy it for usage (BYOC: Bring Your Own Container).

## How to make the most from you AWS free tier
Before, we start read this: [Is the AWS Free Tier really free?](https://www.lastweekinaws.com/blog/is-the-aws-free-tier-really-free/) AWS offers three different kinds of free services. Some are short-term samples, allowing you to evaluate a new service for a month or so. They’re meant to get teams to explore new products without the worry of a bill. AWS is a business and the free tier is a well-designed marketing tool not a public charity. Here are some suggestions how to make the best of the AWS offering:
  - **Go Serverless** AWS Lambda is the only Amazon compute option that remains free after one year. It’s also arguably the best option for a service that will scale smoothly to handle thousands, millions, or billions of requests. Choosing Lambda from the beginning sets your application up for success in the future. Pay attention that this is AWS services in the free tier come with a limit, usually enforced each month. Some of these seem impossibly large like AWS Lambda’s grant of one million function calls. A million can come pretty soon if you’re not careful, so make sure you actually monitor this.
  - **Go Static** The options for computation in the free tier are pretty limited and so it pays to reduce the server-side computation as much as possible. Static site generators like Jekyl or Gatsby turn the data in your dynamic website into HTML, JavaScript, and CSS files that sit out in a static web server.  
  - **Go NoSQL** DynamoDB comes with 20GB of storage space that’s always free. DynamoDB may not offer the same clever indexing and normalization options that relational database lovers have embraced over the years, but NoSQL remains a smart and flexible architectural choice that’s especially forgiving for evolving prototypes and pivoting startups.
  - **Combine AJAX calls** Sometimes you’re going to need to make your site interactive. The best approach is to bundle the calls to your web services into as few transactions as possible. The Amazon API Gateway free tier, for instance, includes one million API calls and one million HTTP calls. Bundling all of your data into one call makes these limits last longer than dutifully invoking the calls immediately. The simplest way to accomplish this is to cut back on storing documents or form data for the user. Yes, this can make the service a bit less robust and crash resistant, but that’s the cost of doing things for free.
  - **Empower the client** While cookies and their lesser known cousins like the local Web Storage API have a reputation for helping big business track people, they also offer the opportunity for users to control their privacy by storing their local data. It also makes it easier to build a free tier web application by offloading the cost of storing client data on the client’s own machine. The users’ machines store the data so you don’t have to!
  - **Avoid gimmicks** Some websites have added flashy interactive features like autocomplete. These may be fun and they may generate attention, but each of these features usually requires another request to the cloud and that eats into your limit. Avoiding unnecessary moving parts is the simplest way to save compute resources.
  - **Run your own database** AWS MySQL or PostgreSQL are great but the free tier only offers you one of them and it’s only for the first 12 months. There’s nothing stopping you from running your own database on one of the free EC2 instances that are also available for the first 12 months.
  - **Log carefully** All of the free storage at AWS comes with limits. Good developers create good log files to debug problems and catch failures, but most log files are never used. Staying within the limits for storage is simpler if you clean out your logs frequently. Some just throw away the data and some download it to their desktop disk.

What happens after the free-credit is exhausted? See [this](https://aws.amazon.com/premiumsupport/knowledge-center/stop-future-free-tier-charges/).

## Resources
- [Build, train, and deploy a machine learning model with Amazon SageMaker](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)
- [Free Machine Learning Services on AWS](https://aws.amazon.com/free/machine-learning/?trk=a422f088-0a19-452b-80fd-deab1be2be30&sc_channel=ps&sc_campaign=acquisition&sc_medium=ACQ-P|PS-GO|Brand|Desktop|SU|Machine%20Learning|Solution|GB|EN|Text&s_kwcid=AL!4422!3!474715178818!p!!g!!%2Bamazon%20%2Bweb%20%2Bservices%20%2Bmachine%20%2Blearning&ef_id=CjwKCAiAprGRBhBgEiwANJEY7BPfUexY9PSb8WzXUXRu25P9guBimJefMIOSkehzdo5wVx09Zm41DxoCZwMQAvD_BwE:G:s&s_kwcid=AL!4422!3!474715178818!p!!g!!%2Bamazon%20%2Bweb%20%2Bservices%20%2Bmachine%20%2Blearning)
- [5 Different Ways to Deploy your Machine Learning Model with AWS](https://towardsdatascience.com/5-different-ways-to-deploy-your-machine-learning-model-with-aws-bd676ab5f8d4)
- [Deploy A Locally Trained ML Model In Cloud Using AWS SageMaker](https://medium.com/geekculture/84af8989d065)
- [Python, Boto3, and AWS S3: Demystified](https://realpython.com/python-boto3-aws-s3/)
- [SageMaker Example Notebooks](https://github.com/aws/amazon-sagemaker-examples)
- [16 videos on Amazon SageMaker Technical Deep Dive Series](https://www.youtube.com/playlist?list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz)
- [What is cloud computing?](https://aws.amazon.com/what-is-cloud-computing/)
- [Find the hands-on tutorials for your AWS needs](https://aws.amazon.com/getting-started/hands-on/?awsf.getting-started-category=category%23compute&awsf.getting-started-content-type=content-type%23hands-on&getting-started-all.sort-by=item.additionalFields.sortOrder&getting-started-all.sort-order=asc&awsf.getting-started-level=*all)
- [How to make the most of the AWS free tier](https://www.infoworld.com/article/3585757/how-to-make-the-most-of-the-aws-free-tier.html)
- [Is the AWS Free Tier really free?](https://www.lastweekinaws.com/blog/is-the-aws-free-tier-really-free/)
- Mishra, Abhishek. Machine Learning in the AWS Cloud: Add Intelligence to Applications with Amazon SageMaker and Amazon Rekognition. John Wiley & Sons, 2019.
