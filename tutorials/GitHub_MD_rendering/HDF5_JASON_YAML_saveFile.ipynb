{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Save your models for later with serialisation (binary format)\n",
    "\n",
    "Keras separates the concerns of saving your model architecture and saving\n",
    "your model weights. Model weights are saved to HDF5 format. This is a \n",
    "grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "The model structure can be described and saved (and loaded) using two \n",
    "different formats: JSON and YAML. Saving and loading your model weights \n",
    "to HDF5 formatted files.\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 & JASON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Hierarchical Data Format or HDF5 for short is a flexible data storage\n",
    "format and is convenient for storing large arrays of real values, as we \n",
    "have in the weights of neural networks.\n",
    "JSON is a simple file format for describing data hierarchically. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.78%\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"../DATASETS/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer = \"uniform\" , activation = \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation = \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\" , activation = \"sigmoid\" ))    \n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer= \"adam\" , metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"../OUTPUT/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../OUTPUT/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 78.78%\n"
     ]
    }
   ],
   "source": [
    "# later...\n",
    "# load json and create model\n",
    "\n",
    "json_file = open(\"../OUTPUT/model.json\" ,  \"r\" )\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")   \n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss= \"binary_crossentropy\" , optimizer= \"rmsprop\" , metrics=[\"accuracy\"])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example is much the same as the above JSON example, except the YAML \n",
    "format is used for the model specification. The model is described using\n",
    "YAML, saved to file model.yaml and later loaded into a new model via the\n",
    "model from yaml() function. Weights are handled in the same way as above\n",
    "in HDF5 format as model.h5.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.34%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"../DATASETS/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer = \"uniform\" , activation = \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation = \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\" , activation = \"sigmoid\" ))    \n",
    "\n",
    "# Compile model\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer= \"adam\" , metrics=[ \"accuracy\" ])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs =150, batch_size=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 77.34%\n"
     ]
    }
   ],
   "source": [
    "# later...\n",
    "# load YAML and create model\n",
    "yaml_file = open( \"model.yaml\" ,  \"r\" )\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss= \"binary_crossentropy\" , optimizer= \"rmsprop\" , metrics=[ \"accuracy\" ])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
